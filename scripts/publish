#!/usr/bin/env bash
# Compile an AFL file and publish it to MongoDB.
#
# Creates a FlowDefinition (for execution) and WorkflowDefinition entries,
# then publishes namespaces to afl_sources for dependency resolution.
#
# Usage:
#   scripts/publish input.afl                                # compile + publish
#   scripts/publish input.afl --version 1.0.0                # with version tag
#   scripts/publish input.afl --auto-resolve --source-path ./libs
#   scripts/publish --primary a.afl --library b.afl          # multi-source
#   scripts/publish input.afl --config /path/to/config.json  # custom config
#
# Options:
#   --config FILE        Path to AFL config file
#   --version TAG        Version tag (default: "latest")
#   --auto-resolve       Automatically resolve missing namespace dependencies
#   --source-path PATH   Additional directory to scan for sources (repeatable)
#   --primary FILE       Primary AFL source file (repeatable)
#   --library FILE       Library/dependency source file (repeatable)
#   --help               Show this help message

set -euo pipefail

REPO_ROOT="$(cd "$(dirname "$0")/.." && pwd)"

PYTHON="${REPO_ROOT}/.venv/bin/python3"
[[ -x "$PYTHON" ]] || PYTHON=python3

CONFIG_ARG=""
VERSION="latest"
AUTO_RESOLVE="false"
INPUT_FILE=""

# Collect repeatable args as newline-separated strings
SOURCE_PATHS=""
PRIMARY_FILES=""
LIBRARY_FILES=""

while [[ $# -gt 0 ]]; do
    case "$1" in
        --config)       CONFIG_ARG="$2"; shift 2 ;;
        --version)      VERSION="$2"; shift 2 ;;
        --auto-resolve) AUTO_RESOLVE="true"; shift ;;
        --source-path)  SOURCE_PATHS="${SOURCE_PATHS}${2}"$'\n'; shift 2 ;;
        --primary)      PRIMARY_FILES="${PRIMARY_FILES}${2}"$'\n'; shift 2 ;;
        --library)      LIBRARY_FILES="${LIBRARY_FILES}${2}"$'\n'; shift 2 ;;
        --help|-h)
            awk 'NR==1{next} /^#/{sub(/^# ?/,""); print; next} {exit}' "$0"
            exit 0
            ;;
        -*)  echo "Unknown option: $1" >&2; exit 1 ;;
        *)   INPUT_FILE="$1"; shift ;;
    esac
done

if [[ -z "$INPUT_FILE" && -z "$PRIMARY_FILES" ]]; then
    echo "Error: provide an input file or --primary FILE." >&2
    echo "Run 'scripts/publish --help' for usage." >&2
    exit 1
fi

exec env PYTHONPATH="$REPO_ROOT" "$PYTHON" -c "
import json
import os
import sys
import time

from pathlib import Path

from afl.config import load_config
from afl.emitter import JSONEmitter
from afl.loader import SourceLoader
from afl.parser import AFLParser
from afl.publisher import SourcePublisher
from afl.runtime.entities import (
    FlowDefinition,
    FlowIdentity,
    SourceText,
    WorkflowDefinition,
)
from afl.runtime.mongo_store import MongoStore
from afl.runtime.types import generate_id
from afl.source import CompilerInput, FileOrigin, SourceEntry
from afl.validator import AFLValidator

config_path = '${CONFIG_ARG}' or None
config = load_config(config_path)

version = '${VERSION}'
auto_resolve = '${AUTO_RESOLVE}' == 'true'
input_file = '${INPUT_FILE}'
source_paths_raw = '''${SOURCE_PATHS}'''.strip()
primary_files_raw = '''${PRIMARY_FILES}'''.strip()
library_files_raw = '''${LIBRARY_FILES}'''.strip()

source_paths = [p for p in source_paths_raw.splitlines() if p.strip()]
primary_files = [p for p in primary_files_raw.splitlines() if p.strip()]
library_files = [p for p in library_files_raw.splitlines() if p.strip()]

# Build CompilerInput
compiler_input = CompilerInput()

if input_file:
    try:
        entry = SourceLoader.load_file(input_file, is_library=False)
        compiler_input.primary_sources.append(entry)
    except FileNotFoundError:
        print(f'Error: File not found: {input_file}', file=sys.stderr)
        sys.exit(1)

for fp in primary_files:
    try:
        entry = SourceLoader.load_file(fp, is_library=False)
        compiler_input.primary_sources.append(entry)
    except FileNotFoundError:
        print(f'Error: File not found: {fp}', file=sys.stderr)
        sys.exit(1)

for fp in library_files:
    try:
        entry = SourceLoader.load_file(fp, is_library=True)
        compiler_input.library_sources.append(entry)
    except FileNotFoundError:
        print(f'Error: File not found: {fp}', file=sys.stderr)
        sys.exit(1)

# Parse
parser = AFLParser()

if auto_resolve:
    if source_paths:
        config.resolver.source_paths.extend(source_paths)
    config.resolver.auto_resolve = True
    ast, source_registry = parser.parse_and_resolve(compiler_input, config)
else:
    ast, source_registry = parser.parse_sources(compiler_input)

# Validate
validator = AFLValidator()
result = validator.validate(ast)
if result.errors:
    for err in result.errors:
        print(f'Validation error: {err}', file=sys.stderr)
    sys.exit(1)

# Emit JSON
emitter = JSONEmitter(include_locations=False)
program_json = emitter.emit(ast)
program_dict = json.loads(program_json)

# Gather all AFL source texts for compiled_sources
all_sources = []
for entry in compiler_input.all_sources:
    from afl.source import FileOrigin as FO
    name = entry.origin.path if isinstance(entry.origin, FO) else entry.source_id
    all_sources.append(SourceText(name=os.path.basename(name), content=entry.text))

# Create FlowDefinition
now_ms = int(time.time() * 1000)
flow_id = generate_id()
flow_name = program_dict.get('workflows', [{}])[0].get('name', 'unnamed') if program_dict.get('workflows') else 'unnamed'

flow = FlowDefinition(
    uuid=flow_id,
    name=FlowIdentity(name=flow_name, path='publish', uuid=flow_id),
    compiled_sources=all_sources,
)

store = MongoStore.from_config(config.mongodb)
store.save_flow(flow)

# Create WorkflowDefinition entries
workflow_names = []
for wf in program_dict.get('workflows', []):
    wf_id = generate_id()
    wf_name = wf.get('name', 'unnamed')
    workflow = WorkflowDefinition(
        uuid=wf_id,
        name=wf_name,
        namespace_id=wf.get('namespace', 'default'),
        facet_id=wf_id,
        flow_id=flow_id,
        starting_step='',
        version=version,
        date=now_ms,
    )
    store.save_workflow(workflow)
    workflow_names.append(wf_name)

# Publish namespaces to afl_sources
publisher = SourcePublisher(store)
ns_count = 0
for entry in compiler_input.all_sources:
    try:
        published = publisher.publish(
            source_text=entry.text,
            version=version,
            origin='publish-script',
            force=True,
        )
        ns_count += len(published)
    except Exception as e:
        # Sources without namespaces are silently skipped
        pass

print()
print(f'Published successfully.')
print(f'  Flow ID:     {flow_id}')
print(f'  Version:     {version}')
print(f'  Workflows:   {', '.join(workflow_names) if workflow_names else '(none)'}')
print(f'  Namespaces:  {ns_count} published to afl_sources')
print(f'  Sources:     {len(compiler_input.all_sources)} file(s)')
print()
"
