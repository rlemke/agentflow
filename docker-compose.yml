# AgentFlow Development Stack
#
# Start with: docker compose up
# Scale with:  docker compose up --scale runner=3 --scale agent-addone=2
# Dashboard: http://localhost:8080
# MongoDB: localhost:27017
#
# Seed example workflows: docker compose --profile seed run --rm seed

services:
  # MongoDB database
  mongodb:
    image: mongo:7
    container_name: afl-mongodb
    ports:
      - "${MONGODB_PORT:-27018}:27017"  # Use 27018 externally to avoid conflicts
    volumes:
      - ${MONGODB_DATA_DIR:-mongodb_data}:/data/db
    healthcheck:
      test: mongosh --eval "db.runCommand('ping').ok" --quiet
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s

  # Web dashboard for monitoring workflows
  dashboard:
    build:
      context: .
      dockerfile: docker/Dockerfile.dashboard
    container_name: afl-dashboard
    ports:
      - "8080:8080"
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
    depends_on:
      mongodb:
        condition: service_healthy
    healthcheck:
      test: curl -f http://localhost:8080/health || exit 1
      interval: 10s
      timeout: 5s
      retries: 3

  # Distributed runner service (scalable)
  runner:
    build:
      context: .
      dockerfile: docker/Dockerfile.runner
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped

  # Sample AddOne agent (scalable)
  agent-addone:
    build:
      context: .
      dockerfile: docker/Dockerfile.agent
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
      - AFL_AGENT_NAME=addone-agent
      - AFL_AGENT_HANDLERS=handlers.AddOne
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped

  # Seed service (runs once to populate example workflows)
  seed:
    build:
      context: .
      dockerfile: docker/Dockerfile.seed
    container_name: afl-seed
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
    depends_on:
      mongodb:
        condition: service_healthy
    profiles:
      - seed

  # OSM Geocoder agent — full image with Java/GraphHopper (scalable)
  agent-osm-geocoder:
    build:
      context: .
      dockerfile: docker/Dockerfile.osm-geocoder
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
    volumes:
      - graphhopper_data:/data/graphhopper
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped

  # OSM Geocoder agent — lite image, no Java/GraphHopper (scalable)
  agent-osm-geocoder-lite:
    build:
      context: .
      dockerfile: docker/Dockerfile.osm-geocoder-lite
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped

  # MCP Server (Model Context Protocol for LLM agents)
  # MCP uses stdio transport, so run interactively:
  #   docker compose --profile mcp run --rm mcp
  mcp:
    build:
      context: .
      dockerfile: docker/Dockerfile.mcp
    container_name: afl-mcp
    environment:
      - AFL_MONGODB_URL=mongodb://mongodb:27017
      - AFL_MONGODB_DATABASE=afl
    depends_on:
      mongodb:
        condition: service_healthy
    stdin_open: true
    tty: true
    profiles:
      - mcp

  # HDFS NameNode — start with: docker compose --profile hdfs up -d
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: afl-namenode
    hostname: namenode
    ports:
      - "9870:9870"   # Web UI
      - "8020:8020"   # RPC (hdfs://namenode:8020)
    environment:
      - CLUSTER_NAME=agentflow
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - HDFS_CONF_dfs_replication=1
    volumes:
      - ${HDFS_NAMENODE_DIR:-hadoop_namenode}:/hadoop/dfs/name
    healthcheck:
      test: curl -f http://localhost:9870 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    profiles:
      - hdfs

  # HDFS DataNode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: afl-datanode
    hostname: datanode
    ports:
      - "9864:9864"   # WebHDFS data transfer
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - SERVICE_PRECONDITION=namenode:8020
    volumes:
      - ${HDFS_DATANODE_DIR:-hadoop_datanode}:/hadoop/dfs/data
    depends_on:
      namenode:
        condition: service_healthy
    profiles:
      - hdfs

  # Jenkins CI/CD — start with: docker compose --profile jenkins up -d
  jenkins:
    image: jenkins/jenkins:lts
    container_name: afl-jenkins
    ports:
      - "9090:8080"   # Web UI
      - "50000:50000" # Agent
    volumes:
      - jenkins_home:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: curl -f http://localhost:8080/login || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 60s
    profiles:
      - jenkins

  # PostGIS database — start with: docker compose --profile postgis up -d
  postgis:
    image: postgis/postgis:16-3.4
    container_name: afl-postgis
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=afl_gis
      - POSTGRES_USER=afl
      - POSTGRES_PASSWORD=afl
    volumes:
      - ${POSTGIS_DATA_DIR:-postgis_data}:/var/lib/postgresql/data
    healthcheck:
      test: pg_isready -U afl
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
    profiles:
      - postgis

volumes:
  mongodb_data:
  graphhopper_data:
  hadoop_namenode:
  hadoop_datanode:
  jenkins_home:
  postgis_data:
